---
layout: post
title: Redis持久化阻塞的问题
tag: 技术笔记
date: 2021-2-3
category: Technology blog
---

##### Redis持久化阻塞的问题

Redis虽然是基于内存的键值对数据库，但是它同时也支持持久化，可以根据自己的业务来判断是否可以当做数据持久化的数据库使用，目前Redis支持两种持久化文件：

- RDB：记录数据某一时刻的快照
- AOF：更新命令已追加的方式写入文件

参数配置与策略之前已经介绍过了，这里我们着重说一下阻塞的问题。

**阻塞**

AOF也是主线程执行的，如果再把日志文件写入磁盘，磁盘压力一大，就会导致写磁盘很慢，就会导致后面的操作阻塞。

同时，随着命令不断从AOF缓存中写入到AOF文件中，AOF文件会越来越大，为了解决这个问题，Redis引入了AOF重写机制来压缩AOF文件。为了避免则色，Redis采用了父子进程来完成重写操作，可以通过命令bgrewriteaof来完成。每次执行重写命令时会有一次复制，和两个日志文件（旧日志文件，和新复制出的日志文件）。Redis会使用到操作系统提供的fork()方法创建子进程来完成复制（不是真正的复制物理，而是虚实映射关系，子进程复制了父进程的页表，也能共享父进程的内存数据，就想拥有了父进程的所有数据一样）操作。子进程再不影响主进程的情况下把数据进行复制重写。fork子进程时，会产生阻塞主线程，因为会复制父进程的数据到子进程，但是fork不会把所有的内存数据都copy到子进程，只会copy一部分有用的数据到子进程中。同时fork采用到操作系统的写时复制机制，每当有新的写命令，就会触发这个机制，此时就会把这新的命令写到旧AOF日志文件的缓冲区，等待数据重写完成后，重写的日志与缓冲区修改的数据进行合并，这样保证了AOF再父子进程之间的数据同步，再就是再重写时可以对外提供操作。fork在复制内存页的时候会大量的消耗CPU资源，如果复制的内存页越大，fork阻塞的时间就会越久。拷贝内存页完成，子进程与父进程指向相同的内存地址。父子进程分离：fork出的子进程与父进程指向的时同样的地址空间，然后子进程就可以完成AOF重写了，在这个过程中如果父进程有新的写命令，父进程会为这个key申请新的内存空间，慢慢的就会让父进程内存数据渐渐的进行分离。

当redis生成dump.rdb文件时，工作过程相同，redis主进程fork一个子进程，fork出来的子进程将内存的数据集dump到临时的RDB中，当子进程对临时的RDB文件写入完毕，redis用新的RDB文件代替旧的RDB文件，dump可能会出现主进程阻塞的现象

##### 监控AOF与RDB持久化处理的状态

运行Redis-cli，输入命令**info Persistence**

```java
# Persistence
loading:0 //标志位，是否在载入数据文件，0代表没有，1代表正在载入
rdb_changes_since_last_save:227721 //从最近一次dump快照后，未被dump的变更次数(和save里变更计数器类似)
rdb_bgsave_in_progress:0 //标志位，记录当前是否在创建RDB快照
rdb_last_save_time:1611283276 //最近一次创建RDB快照文件的Unix时间戳
rdb_last_bgsave_status:ok //标志位，记录最近一次bgsave操作是否创建成功
rdb_last_bgsave_time_sec:61 //最近一次bgsave操作耗时秒数
rdb_current_bgsave_time_sec:-1 //当前bgsave执行耗时秒数(-1 还没有执行)
aof_enabled:1 //appenonly是否开启,appendonly为yes则为1,no则为0
aof_rewrite_in_progress:0 //AOF重写是否正在进行
aof_rewrite_scheduled:0 //AOF重写是否被RDB save操作阻塞等待
aof_last_rewrite_time_sec:1 //最近一次AOF重写操作耗时
aof_current_rewrite_time_sec:-1 //当前AOF重写持续的耗时
aof_last_bgrewrite_status:ok //最近一次AOF重写操作是否成功
aof_last_write_status:ok //最近一次AOF写入操作是否成功
aof_current_size:78056671 //AOF 文件目前的大小 字节
aof_base_size:50531725 //服务器启动时或者 AOF 重写最近一次执行之后，AOF 文件的大小
aof_pending_rewrite:0 //是否有 AOF 重写操作在等待 RDB 文件创建完毕之后执行
aof_buffer_length:0 //AOF 缓冲区的大小
aof_rewrite_buffer_length:0 //AOF 重写缓冲区的大小
aof_pending_bio_fsync:0 //后台 I/O 队列里面，等待执行的 fsync 调用数量
aof_delayed_fsync:0 //被延迟的 fsync 调用数量

```
##### 策略

目前服务器内存使用率很高，IO竞争很高，暂时关闭了RDB持久化，只是单单使用AOF，其中AOF参数优化

```java
appendfsync: no //写入aof文件，不等待磁盘同步，避免造成IO竞争
no-appendfsync-on-rewrite: yes // 只是写入了缓冲区，因此这样并不会造成阻塞
```



##### MQ队列消息堆积问题

在ActiveMQ中，由于Topic队列没有消费方，而且生产方也一直在推送信息数据到队列中，导致大量的消息挤压。

这里阐述一下在目前在MQ有关于消息队列配置的配置项

**为持久化消息设置过期时间**

ActiveMQ提供了一个timeStampingBrokerPlugin插件，通过此插件，我们可以为持久化消息设置过期时间

```java
<plugins>
<!-- 86,400,000 ms = 1 day -->
<timeStampingBrokerPlugin ttlCeiling="86400000" zeroExpirationOverride="86400000"/>
</plugins>
```

zeroExpirationOverride: 会为没有设置过期时间的消息设置过期时间

ttlCeiling: 过期时间上限

**删除空的Queue和Topic**

```java
<broker xmlns="http://activemq.apache.org/schema/core" schedulePeriodForDestinationPurge="10000">

<destinationPolicy>
<policyMap>
<policyEntries>
<policyEntry queue=">" gcInactiveDestinations="true" inactiveTimoutBeforeGC="30000"/>
</policyEntries>
</policyMap>
</destinationPolicy>

</broker>
```

schedulePeriodForDestinationPurge：执行清理任务的周期；
gcInactiveDestinations=true：表示启用清理功能；
inactiveTimoutBeforeGC：queue或topic的超时时间，在规定的时间内，无有效订阅，没有入队记。

##### Redis在运行中时常出现连接timeout的问题，服务整个处于一个假死的状态

Redis在运行中时常出现连接timeout的问题，服务整个处于一个假死的状态

使用redis-cli中**info Memory**监控redis内存的使用情况

```java
# Memory
used_memory:95452640//Redis已分配的内存总量（字节单位形式）
used_memory_human:91.03M//Redis已分配的内存总量（易读单位形式）
used_memory_rss:105975808
used_memory_rss_human:101.07M//操作系统为Redis进程分配的内存总量
used_memory_peak:108178320
used_memory_peak_human:103.17M//最大使用内存总量（峰值）
total_system_memory:16610439168
total_system_memory_human:15.47G
used_memory_lua:37888
used_memory_lua_human:37.00K
maxmemory:2147483648
maxmemory_human:2.00G//最大的内存限制，0表示无限制
maxmemory_policy:allkeys-lru//超过内存限制后的处理策略
mem_fragmentation_ratio:1.11//碎片率， >1表示有碎片， <1表示部分Redis的内存被系统交换到硬盘（此时Redis性能变差）
mem_allocator:jemalloc-4.0.3
```

这里需要注意一下一个参数

**mem_fragmentation_ratio**

info信息中的**mem_fragmentation_ratio**给出了内存碎片率的数据指标，它是由操作系统分配的内存除以Redis分配的内存得出：

**mem_fragmentation_ratio** = **Used Memory RSS / Used Memory**

used_memory和used_memory_rss数字都包含的内存分配有：

- 用户定义的数据：内存被用来存储key-value值。
- 内部开销：存储内部Redis信息用来表示不用的数据类型。

uesd_memory_rss的rss是Resident Set Size的缩写，表示该进程所占物理内存的大小，是操作系统分配给Redis实例的内存大小，除了用户定义的数据和内部开销以外，used_memory_rss指标还包含了内存碎片的开销，内存碎片是由操作系统低效的分配/回收物理内存导致的。

操作系统负责分配物理内存给各个应用进程，Redis使用的内存与物理内存的映射是由操作系统上虚拟内存管理分配器完成的。

举个例子来说，Redis需要分配连续内存块来存储1G的数据集，这样的话更有利，但可能物理内存上没有超过1G的连续内存块，那操作系统就不得不使用多个不连续的小内存块来分配并存储这1G数据，也就导致内存碎片的产生。

内存分配器是另一个复杂的层面，它经常会预先分配一些内存块给引用，这样做会加快应用程序的运行。
##### 理解资源性能

跟踪内存碎片率对理解Redis实例的资源性能是非常重要的，内存碎片率稍大于1是合理的，这个值就表示内存碎片率比较低，也说明redis没有发生内存交换，但如果内存碎片率超过1.5，那就说明Redis消耗了实际需要物理内存的150%，其中50%是内存碎片率，若是内存碎片率低于1的话，说明Redis内存分配超出了物理内存，操作系统正在进行内存交换，内存交换会引起非常明显的响应延迟。

**因内存交换引起的性能问题**

内存使用率是Redis服务最关键的一部分。如果一个Redis实例的内存使用率超过可用最大内存 (used_memory > 可用最大内存)，那么操作系统开始进行内存与swap空间交换，把内存中旧的或不再使用的内容写入硬盘上（硬盘上的这块空间叫Swap分区），以便腾出新的物理内存给新页或活动页(page)使用。
在硬盘上进行读写操作要比在内存上进行读写操作，时间上慢了近5个数量级，内存是0.1μs单位、而硬盘是10ms。如果Redis进程上发生内存交换，那么Redis和依赖Redis上数据的应用会受到严重的性能影响。 通过查看used_memory指标可知道Redis正在使用的内存情况，如果used_memory>可用最大内存，那就说明Redis实例正在进行内存交换或者已经内存交换完毕。管理员根据这个情况，执行相对应的应急措施。

**跟踪内存使用率**

若是在使用Redis期间没有开启rdb快照或aof持久化策略，那么缓存数据在Redis崩溃时就有丢失的危险。因为当Redis内存使用率超过可用内存的95%时，部分数据开始在内存与swap空间来回交换，这时就可能有丢失数据的危险。
当开启并触发快照功能时，Redis会fork一个子进程把当前内存中的数据完全复制一份写入到硬盘上。因此若是当前使用内存超过可用内存的45%时触发快照功能，那么此时进行的内存交换会变的非常危险(可能会丢失数据)。 倘若在这个时候实例上有大量频繁的更新操作，问题会变得更加严重。

通过减少Redis的内存占用率，来避免这样的问题，或者使用下面的技巧来避免内存交换发生：

1. 假如缓存数据小于4GB，就使用32位的Redis实例。因为32位实例上的指针大小只有64位的一半，它的内存空间占用空间会更少些。 这有一个坏处就是，假设物理内存超过4GB，那么32位实例能使用的内存仍然会被限制在4GB以下。 要是实例同时也共享给其他一些应用使用的话，那可能需要更高效的64位Redis实例，这种情况下切换到32位是不可取的。 不管使用哪种方式，Redis的dump文件在32位和64位之间是互相兼容的， 因此倘若有减少占用内存空间的需求，可以尝试先使用32位，后面再切换到64位上。
2. 尽可能的使用Hash数据结构。因为Redis在储存小于100个字段的Hash结构上，其存储效率是非常高的。所以在不需要集合(set)操作或list的push/pop操作的时候，尽可能的使用Hash结构。比如，在一个web应用程序中，需要存储一个对象表示用户信息，使用单个key表示一个用户，其每个属性存储在Hash的字段里，这样要比给每个属性单独设置一个key-value要高效的多。 通常情况下倘若有数据使用string结构，用多个key存储时，那么应该转换成单key多字段的Hash结构。 如上述例子中介绍的Hash结构应包含，单个对象的属性或者单个用户各种各样的资料。Hash结构的操作命令是HSET(key, fields, value)和HGET(key, field)，使用它可以存储或从Hash中取出指定的字段。
3. 设置key的过期时间。一个减少内存使用率的简单方法就是，每当存储对象时确保设置key的过期时间。倘若key在明确的时间周期内使用或者旧key不大可能被使用时，就可以用Redis过期时间命令(expire,expireat, pexpire, pexpireat)去设置过期时间，这样Redis会在key过期时自动删除key。 假如你知道每秒钟有多少个新key-value被创建，那可以调整key的存活时间，并指定阀值去限制Redis使用的最大内存。
4. 回收key。在Redis配置文件中(一般叫Redis.conf)，通过设置“maxmemory”属性的值可以限制Redis最大使用的内存，修改后重启实例生效。 也可以使用客户端命令config set maxmemory 去修改值，这个命令是立即生效的，但会在重启后会失效，需要使用config rewrite命令去刷新配置文件。 若是启用了Redis快照功能，应该设置“maxmemory”值为系统可使用内存的45%，因为快照时需要一倍的内存来复制整个数据集，也就是说如果当前已使用45%，在快照期间会变成95%(45%+45%+5%)，其中5%是预留给其他的开销。 如果没开启快照功能，maxmemory最高能设置为系统可用内存的95%。

当内存使用达到设置的最大阀值时，需要选择一种key的回收策略，可在Redis.conf配置文件中修改“maxmemory-policy”属性值。 若是Redis数据集中的key都设置了过期时间，那么“volatile-ttl”策略是比较好的选择。但如果key在达到最大内存限制时没能够迅速过期，或者根本没有设置过期时间。那么设置为“allkeys-lru”值比较合适，它允许Redis从整个数据集中挑选最近最少使用的key进行删除(LRU淘汰算法)。Redis还提供了一些其他淘汰策略，如下：

- volatile-lru：使用LRU算法从已设置过期时间的数据集合中淘汰数据。
- volatile-ttl：从已设置过期时间的数据集合中挑选即将过期的数据淘汰。
- volatile-random：从已设置过期时间的数据集合中随机挑选数据淘汰。
- allkeys-lru：使用LRU算法从所有数据集合中淘汰数据。
- allkeys-random：从数据集合中任意选择数据淘汰
- no-enviction：禁止淘汰数据。

通过设置maxmemory为系统可用内存的45%或95%(取决于持久化策略)和设置“maxmemory-policy”为“volatile-ttl”或“allkeys-lru”(取决于过期设置)，可以比较准确的限制Redis最大内存使用率，在绝大多数场景下使用这2种方式可确保Redis不会进行内存交换。倘若你担心由于限制了内存使用率导致丢失数据的话，可以设置noneviction值禁止淘汰数据。


##### 拓展

一些性能相关的数据指标

通过Redis-cli命令行界面访问到Redis服务器，然后使用info命令获取所有与Redis服务组相关的信息，通过这些信息来监控Redis的运行状态。

info命令输出的数据可分为10个类别，分别是：

- server
- clients
- memory
- persistence
- stats
- replication
- cpu
- commandstats
- cluster
- keyspace


[AOF持久化](https://blog.csdn.net/qq_45422703/article/details/109588607)

[Redis性能问题排查解决手册(七)](https://www.cnblogs.com/mushroom/p/4738170.html)